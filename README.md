# Fashion Forward Hub - Advanced RAG Chatbot

A production-grade Retrieval-Augmented Generation (RAG) chatbot for fashion e-commerce, featuring multiple retrieval strategies, JWT authentication, comprehensive testing, and full observability.

## ğŸš€ Key Highlights:

- ğŸ“„ **3 Retrieval Strategies:** BM25 (keyword), Semantic (vector), Hybrid (RRF fusion)
- ğŸ§  **Smart Metadata Filtering:** LLM-powered filter extraction for precise product search
- ğŸ” **Cross-Encoder Reranking:**  Enhanced result relevance
- â˜ï¸ **Phoenix Observability:** Full tracing of RAG pipeline
- ğŸ’¬ **Production Security:** JWT auth + Redis rate limiting
- ğŸ” **Comprehensive Testing:** Unit, Integration, Evaluation, Performance tests

  
## ğŸš€ What This Project Does

- **ğŸ›ï¸ Answers fashion e-commerce queries** using RAG (FAQ + Product search)
- **ğŸ§  Intelligently routes queries** to FAQ or Product databases
- **ğŸ” Multiple retrieval strategies** - BM25, Semantic, Hybrid with configurable parameters
- **ğŸ¯ Metadata filtering** - Extracts filters (color, price, gender, etc.) from natural language
- **ğŸ“Š Full observability** - Phoenix tracing tracks every step of the pipeline
- **ğŸ” Production-ready**  - JWT authentication, rate limiting, input validation
- **âœ… Quality assured** - RAGAS metrics, performance benchmarks, regression tests


## ğŸ—ï¸ Architecture Diagram

  
```mermaid
flowchart TB
    subgraph Client["ğŸ‘¤ Client Layer"]
        Browser["ğŸŒ Web Browser"]
        UI["ğŸ¨ Chat Interface<br/>(HTML/CSS/JS)"]
    end

    subgraph Auth["ğŸ” Authentication & Security"]
        JWT["ğŸ« JWT Tokens<br/>(Flask-JWT-Extended)"]
        RateLimit["â±ï¸ Rate Limiter<br/>(Flask-Limiter + Redis)"]
        AuthService["ğŸ‘¥ Auth Service<br/>(User Management)"]
    end

    subgraph API["ğŸš€ Flask API Server (Port 8000)"]
        Routes["ğŸ“ API Routes<br/>/api/login, /api/register<br/>/api/chat, /api/clear"]
        SessionMgr["ğŸ“¦ Session Manager<br/>(ChatBot per user)"]
        Validation["âœ… Input Validation<br/>(Pydantic Schemas)"]
    end

    subgraph RAG["ğŸ§  RAG Pipeline"]
        Router["ğŸ§­ Query Router<br/>(FAQ vs Product)<br/>LLM Classification"]
        
        subgraph Retrieval["ğŸ” Multi-Strategy Retrieval"]
            BM25["ğŸ“ BM25<br/>(Keyword Search)"]
            Semantic["ğŸ¯ Semantic<br/>(Vector Search)"]
            Hybrid["âš–ï¸ Hybrid<br/>(BM25 + Semantic + RRF)"]
        end
        
        MetaFilter["ğŸ·ï¸ Metadata Filter<br/>(LLM Extraction)<br/>color, price, gender"]
        Reranker["ğŸ”„ Cross-Encoder<br/>Reranker<br/>(ms-marco-MiniLM)"]
        Generator["âœ¨ Answer Generator<br/>(GPT-4o-mini)"]
    end

    subgraph DataLayer["ğŸ’¾ Data Layer"]
        Weaviate[("ğŸ—„ï¸ Weaviate<br/>Vector Database<br/>Port 8080<br/><br/>44K Products<br/>25 FAQs")]
        Redis[("ğŸ”´ Redis<br/>Cache Store<br/>Port 6379<br/><br/>Auth Sessions<br/>Rate Limits")]
    end

    subgraph External["â˜ï¸ External Services"]
        OpenAI["ğŸ¤– OpenAI API<br/>GPT-4o-mini<br/><br/>Routing<br/>Metadata<br/>Answer Gen"]
    end

    subgraph Observability["ğŸ“Š Observability"]
        Phoenix["ğŸ”¥ Phoenix Dashboard<br/>Port 6006<br/><br/>Request Traces<br/>Token Usage<br/>Performance"]
        Logs["ğŸ“ Application Logs<br/>(Python logging)"]
    end

    %% Client connections
    Browser --> UI
    UI -->|"HTTP + JWT"| Routes

    %% API flow
    Routes --> JWT
    Routes --> RateLimit
    JWT --> AuthService
    RateLimit --> Redis
    AuthService --> Redis
    
    Routes --> Validation
    Validation --> SessionMgr
    
    %% RAG Pipeline
    SessionMgr --> Router
    Router --> OpenAI
    
    Router -->|"FAQ Query"| Weaviate
    Router -->|"Product Query"| MetaFilter
    
    MetaFilter --> OpenAI
    MetaFilter --> BM25
    MetaFilter --> Semantic
    MetaFilter --> Hybrid
    
    BM25 --> Weaviate
    Semantic --> Weaviate
    Hybrid --> Weaviate
    
    BM25 --> Reranker
    Semantic --> Reranker
    Hybrid --> Reranker
    
    Reranker --> Generator
    Generator --> OpenAI
    Generator --> SessionMgr
    
    %% Observability
    Router -.->|"Trace"| Phoenix
    MetaFilter -.->|"Trace"| Phoenix
    Retrieval -.->|"Trace"| Phoenix
    Generator -.->|"Trace"| Phoenix
    SessionMgr -.->|"Logs"| Logs

    %% Styling
    classDef client fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    classDef auth fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef api fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef rag fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef data fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef external fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    classDef observ fill:#e0f2f1,stroke:#004d40,stroke-width:2px

    class Browser,UI client
    class JWT,RateLimit,AuthService auth
    class Routes,SessionMgr,Validation api
    class Router,BM25,Semantic,Hybrid,MetaFilter,Reranker,Generator,Retrieval rag
    class Weaviate,Redis data
    class OpenAI external
    class Phoenix,Logs observ
```
---
## ğŸ—ï¸ Execution Sequence (End-to-End)
```mermaid
sequenceDiagram
    participant U as User (Browser)
    participant F as Flask API
    participant A as Auth (JWT + Redis)
    participant C as ChatBot
    participant R as RAG Pipeline
    participant Q as Query Router
    participant M as Metadata Filter
    participant W as Weaviate
    participant RR as Reranker
    participant L as OpenAI LLM
    participant P as Phoenix

    U->>F: POST /api/chat + JWT token
    F->>A: Verify JWT + Rate limit
    A-->>F: âœ“ Authorized
    
    F->>C: chatbot.chat(query, params)
    
    Note over C,R: Start RAG Pipeline
    C->>R: answer_query(query, use_rag, retriever, etc.)
    R->>P: Start span "answer_query"
    
    alt use_rag = False
        R->>L: Direct LLM call (no retrieval)
        L-->>R: Generic answer
    else use_rag = True
        R->>Q: Route query (FAQ vs Product)
        Q->>L: LLM classification
        L-->>Q: Label: "Product"
        Q-->>R: Route: Product
        
        Note over R,M: Metadata Extraction
        R->>M: generate_filters_from_query(query)
        M->>L: Extract filters (color, price, etc.)
        L-->>M: {"baseColour": ["Blue"], "price": {"max": 50}}
        M-->>R: Weaviate filters
        
        Note over R,W: Multi-Strategy Retrieval
        alt retriever_type = BM25
            R->>W: BM25 keyword search
        else retriever_type = Semantic
            R->>W: Vector search + filters
        else retriever_type = Hybrid
            R->>W: BM25 + Semantic
            R->>R: RRF fusion (alpha, k)
        end
        W-->>R: Top-K products
        
        opt use_reranker = True
            R->>RR: Cross-encoder rerank
            RR-->>R: Reranked results
        end
        
        R->>L: Generate answer with context
        L-->>R: Product recommendations
    end
    
    R->>P: End span + attributes
    R-->>C: Answer + tokens
    C-->>F: Response + stats
    F-->>U: JSON response
```

**ğŸ—ï¸ Detailed Architecture Flow**
### 1ï¸âƒ£ Authentication & Rate Limiting
```bash
User Request
    â†“
JWT Verification (Flask-JWT-Extended)
    â”œâ”€ Valid? â†’ Continue
    â””â”€ Invalid? â†’ 401 Unauthorized
    â†“
Rate Limiting (Flask-Limiter + Redis)
    â”œâ”€ 20 chat requests/min per user
    â”œâ”€ 100 total requests/hour per user
    â”œâ”€ 10 login attempts/hour per IP
    â””â”€ 5 register attempts/hour per IP
    â†“
Request proceeds to ChatBot
```
### 2ï¸âƒ£ Query Routing (FAQ vs Product)
```bash
Query: "What is your return policy?"
    â†“
check_if_faq_or_product(query)
    â†“
LLM Classification (GPT-4o-mini, temp=0)
    â”œâ”€ Analyzes query intent
    â”œâ”€ Examples-based few-shot
    â””â”€ Output: "FAQ" or "Product"
    â†“
Route to appropriate handler
```
### 3ï¸âƒ£ Product Retrieval Pipeline
```bash
Query: "blue shirts under $50"
    â†“
Metadata Extraction (if simplified=False)
    â”œâ”€ LLM extracts structured filters
    â”œâ”€ {"baseColour": ["Blue"], "price": {"max": 50}}
    â””â”€ Convert to Weaviate filters
    â†“
Retrieval Strategy Selection
    â”œâ”€ BM25: Keyword-based (TF-IDF)
    â”œâ”€ Semantic: Vector similarity + filters
    â””â”€ Hybrid: BM25 + Semantic + RRF fusion
    â†“
Optional Reranking
    â”œâ”€ Cross-encoder model
    â””â”€ Reorders by relevance score
    â†“
Top-K Products Retrieved
    â†“
Generate LLM Response
    â””â”€ Context: Product list + metadata
```
### 4ï¸âƒ£ Hybrid Retrieval (RRF Fusion)
```bash
Reciprocal Rank Fusion (RRF)
    â†“
1. BM25 Search â†’ Results A (keyword match)
2. Semantic Search â†’ Results B (meaning match)
    â†“
3. Score each result:
   score = Î±/(k + rank_bm25) + (1-Î±)/(k + rank_semantic)
   
   where:
   - Î± (alpha): Weight for BM25 (0.0 to 1.0)
   - k: RRF constant (typically 60)
    â†“
4. Sort by combined score
5. Return top-K fused results

Example:
Î± = 0.5: Equal weight to keyword and semantic
Î± = 0.8: Favor keyword matching
Î± = 0.2: Favor semantic similarity
```
---

## ğŸ“ Project Structure
```text
ChatBot/
â”œâ”€â”€ src/                                  # Core application code
â”‚   â”œâ”€â”€ interface/
â”‚   â”‚   â””â”€â”€ web_app.py                   # Flask API (JWT, rate limiting, endpoints)
â”‚   â”œâ”€â”€ auth.py                          # User authentication service
â”‚   â”œâ”€â”€ chatbot.py                       # Conversation manager
â”‚   â”œâ”€â”€ config.py                        # Configuration (env variables)
â”‚   â”œâ”€â”€ database.py                      # Weaviate client
â”‚   â”œâ”€â”€ llm.py                           # OpenAI API wrapper
â”‚   â”œâ”€â”€ metadata_filter.py               # LLM-based filter extraction
â”‚   â”œâ”€â”€ models.py                        # User model (password hashing)
â”‚   â”œâ”€â”€ query_router.py                  # FAQ vs Product classification
â”‚   â”œâ”€â”€ rag_pipeline.py                  # Main RAG orchestration
â”‚   â”œâ”€â”€ reranker.py                      # Cross-encoder reranking
â”‚   â”œâ”€â”€ schemas.py                       # Pydantic validation models
â”‚   â””â”€â”€ tracer.py                        # Phoenix OpenTelemetry setup
â”‚
â”œâ”€â”€ static/                               # Frontend assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ auth.css                     # Login/register styling
â”‚   â”‚   â””â”€â”€ style.css                    # Chat UI styling
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ auth.js                      # Login/register logic
â”‚       â””â”€â”€ chat.js                      # Chat interface logic
â”‚
â”œâ”€â”€ templates/                            # HTML templates
â”‚   â”œâ”€â”€ index.html                       # Login/register page
â”‚   â””â”€â”€ chat.html                        # Chat interface
â”‚
â”œâ”€â”€ tests/                                # Comprehensive test suite
â”‚   â”œâ”€â”€ conftest.py                      # Pytest fixtures
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â””â”€â”€ test_retrieval.py           # BM25, Semantic, Hybrid tests
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ test_rag_pipeline.py        # End-to-end pipeline tests
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ test_rag_quality.py         # RAGAS metrics
â”‚   â”‚   â””â”€â”€ test_performance.py         # Latency & regression tests
â”‚   â””â”€â”€ run_tests.py                    # Test runner script
â”‚
â”œâ”€â”€ data/                                 # Data files (not in repo)
â”‚   â”œâ”€â”€ clothes.csv                      # Product catalog (44K items)
â”‚   â”œâ”€â”€ clothes_json.joblib              # Processed product data
â”‚   â”œâ”€â”€ faq.csv                          # FAQ database
â”‚   â””â”€â”€ faq_or_products.csv             # Training data for router
â”‚
â”œâ”€â”€ docker-compose.yml                    # Weaviate + Phoenix + Redis
â”œâ”€â”€ .env                                 # Environment variables
â”œâ”€â”€ .gitignore                           # Git ignore rules
â”œâ”€â”€ pyproject.toml                       # Python dependencies
â””â”€â”€ README.md                            # This file
```
---
## ğŸ› ï¸ Prerequisites

### Required Software
- **Python 3.11+** (recommended via `.python-version`)
- **[`uv`](https://github.com/astral-sh/uv)** â€“ fast Python package & environment manager
- **Docker & Docker Compose (for Weaviate, Phoenix, Redis)**
- **Git**
  
### Required Services:
- **OpenAI API Key (GPT-4o-mini access)**
- **Weaviate (vector database)**
- **Redis (authentication + rate limiting)**
- **Phoenix (observability dashboard)**

### System Requirements:
- **RAM: 8GB minimum (Weaviate + embeddings)**
- **Disk: 5GB for vector indices**
- **CPU: Multi-core recommended for reranking**

---
## âš™ï¸ Setup Instructions

Follow these steps to run the **Fashion Forward Hub RAG Chatbot** system locally.

---

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/AvinashBolleddula/Fashion-Forward-Hub.git
cd fashion-forward-hub-rag
```

### 2ï¸âƒ£ Create and activate a virtual environment
This project uses uv for fast and reproducible Python environments.
```bash
uv venv
source .venv/bin/activate
```
You should now see (.venv) in your terminal prompt.

### 3ï¸âƒ£ Install dependencies
Install all required dependencies exactly as defined in pyproject.toml and uv.lock.
```bash
uv sync
```
### 4ï¸âƒ£ Configure environment variables
Create a .env file inside the weather/ directory:
```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# Weaviate Configuration
WEAVIATE_URL=http://localhost:8080
WEAVIATE_HOST=localhost
WEAVIATE_PORT=8080

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# Flask Configuration
FLASK_HOST=0.0.0.0
FLASK_PORT=8000
FLASK_DEBUG=True

# JWT Configuration
JWT_SECRET_KEY=your-super-secret-key-change-in-production
JWT_ACCESS_TOKEN_EXPIRES=3600

# Rate Limiting
RATE_LIMIT_DEFAULT=100/hour
RATE_LIMIT_CHAT=20/minute

# Phoenix Configuration (Optional)
PHOENIX_PORT=6006

# Context Window
CONTEXT_WINDOW=10
```

### 5ï¸âƒ£ Start Docker Services
Start Weaviate, Redis, and Phoenix:
```bash
docker-compose up -d

```
Verify services are running:
```bash
docker-compose ps

```
You should see:

weaviate on port 8080
redis on port 6379
phoenix on port 6006


### 6ï¸âƒ£  Load Data into Weaviate
Option A: Use Pre-loaded Data (Recommended)
If you have the vector database already populated:

```bash
# Database should persist in ./weaviate-data/
# Just start docker-compose and collections are available
```
Option B: Load Data Manually

```bash
# 1. Ensure data files exist in ./data/
ls data/
# Should show: clothes.csv, faq.csv, clothes_json.joblib, faq_or_products.csv

# 2. Run data loading scripts (if available)
python scripts/load_products.py
python scripts/load_faqs.py
```

### Run the Flask Application
```bash
python src/database.py
```
You should see output similar to:
```bash
INFO:__main__:Starting Flask app on 0.0.0.0:8000
 * Running on http://0.0.0.0:8000
```
Open your browser at:
```bash
http://localhost:8000
```
You'll see the login/register page.

### 6ï¸âƒ£ Create an Account & Start Chatting
- **1.	Register a new account**
- **2.	Login with your credentials**
- **3.	Start asking questions!**

## Ask questions ğŸ¯
### Example query:

- **â€œWhat is your return policy?â€**
- **â€œShow me blue shirts under $50â€**
- **â€œDo you have casual summer wear for men?â€**

## ğŸ§ª Testing

Run All Tests

```bash
# Using test runner
python tests/run_tests.py all

# Or using pytest directly
pytest tests/ -v
```

## ğŸ“Š Observability (Phoenix Dashboard)

Access Phoenix at: http://localhost:6006

### What You Can Track:

- **Request Traces**
- **Query Routing**
- **Retrieval Performance**
- **LLM Calls**
- **End-to-End Metrics**

Example Trace View
```bash
answer_query (2.8s)
â”œâ”€ routing_faq_or_product (1.2s)
â”‚  â””â”€ Attributes: {"label": "Product", "tokens": 50}
â”œâ”€ generate_metadata (1.5s)
â”‚  â””â”€ Attributes: {"filters": 2, "tokens": 1366}
â”œâ”€ retrieve_semantic (0.8s)
â”‚  â””â”€ Attributes: {"num_results": 15, "has_filters": true}
â””â”€ final_llm_call (0.9s)
   â””â”€ Attributes: {"tokens": 856}
```


## ğŸš€ Future Enhancements

### Planned Features

- **Caching Layers**
- **Conversation Memory**
- **Advanced Analytics**
- **Multi-Modal Support**
- **Deployment**
- **Enhanced Retrieval**
